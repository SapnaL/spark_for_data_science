{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD Lab\n",
    "\n",
    "In this lab, we will be working with data from [Libraries.io](http://Libraries.io), a package manager aggregator. Our data consist of two files, one detailing packages and package managers, the other detailing the code repositories the packages are developed in. \n",
    "\n",
    "The data is stored as csv files, so to get started import the needed Python packages and read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = spark.sparkContext.textFile(\"hdfs:///data/projects-1.0.0-2017-06-15.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the data was read in correctly using take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that what we read in is a list of strings. Further more, the first string appears to a column headers. \n",
    "\n",
    "In the next cell we are going to split each string into a tuple. We have done this step for you, but make sure you can understand what the code below is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = text.map(lambda x: tuple(next(csv.reader(StringIO(x)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split each line into tuples, we need to remove the first row, which isn't actually part of the data. \n",
    "\n",
    "To do this, use the `filter` function and write a lambda that checks if the first element of the tuple is **not** \"ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, use take to look at the format the data is now in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the lab consists of answering questions about the data. \n",
    "\n",
    "### How many packages are accounted for in this dataset?\n",
    "\n",
    "Hint: Use `count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What package managers are included in the data?\n",
    "\n",
    "The package manager is the second element in each tuple in the RDD, and can be accseed using `tuple[1]`\n",
    "\n",
    "Hint: Extract the package manager names using `map` and then use `distinct`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the results using `collect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What package has the higest SourceRank?\n",
    "\n",
    "SourceRank is Libraries.io measure that combines popularity as well as how well maintained the packages is, along with a few other factors\n",
    "\n",
    "We've done this one for you to show you a unique way to use Python's built in `max` function.\n",
    "\n",
    "By supplying a key to the `max` function we can compare two tuples using a sepcific element in that tuple. In this case we are comparing source rank, which we can access at the 11th position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reduce(lambda x,y: max(x,y,key=lambda tup: int(tup[11])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the most frequent dependency per package manager?\n",
    "\n",
    "To answer this question, let's break it down into smaller parts. \n",
    "\n",
    "First it is a good idea to change the RDD into a Pair RDD, using the package manager as the key. We have done this step for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_manager_keys = data.map(lambda x: (x[1],x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use `reduceByKey` to find the most frequent dependency in each package manager.\n",
    "\n",
    "Use the built in `max` function from Python, similiarly to as was done above. The element of the tuple you should be comparing on this time is `19`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_deps = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use `map` again to select only the package manager, the package name, and the number of times it is listed as a dependency.\n",
    "\n",
    "Remember, the RDD elements now have a form of\n",
    "\n",
    "`(packageMananger, (packageMananger, packageName, .... )`\n",
    "\n",
    "The packageName can be accessed using `tupleVar[1][2]` and the number of times it is a dependency can be acessed using `tupleVar[1][19]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformatted = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the most popular dependencies using `collect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who is the most proflific owner of packages per package manager?\n",
    "\n",
    "For this next question, we need to consult the second file, which is detailed information about where and who develops each package. Reading in the data will be very similar to as was done above, so we have taken all the steps to split each line and filter the data for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = spark.sparkContext.textFile(\"hdfs:///data/repositories-1.0.0-2017-06-15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_data = repos.map(lambda x: tuple(next(csv.reader(StringIO(x),'unix')))).filter(lambda x: x[0] != \"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question we are going to join our two RDDs together. In order to do that, first we need to once again convert them into a Pair RDD, this time with the primary key from the repository dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `map` to make a (key,value) pair for each element in the `repos_data` RDD. The tuple index for the key is `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_to_join = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `map` to make a (key, value) pair for each element in the `data` RDD. The tuple index for the key is `-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_join = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `join` to join the two RDDs together into a single RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a single RDD, we can prepare to count the number of packages each owner has in each package manager. We have done this step for you. \n",
    "\n",
    "What the code below is doing is creating a tuple of the form\n",
    "\n",
    "`((packageManager, repositoryOwner), 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_owners = joined.map(lambda x: ((x[1][0][1],x[1][1][2].split('/')[0]),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `reduceByKey` to add up the total number for reach `packageManager,reposititoryOwner` pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `map` to reformat the data so just the package manager is the key now.\n",
    "\n",
    "The data looked like \n",
    "\n",
    "`((packageManager, repositoryOwner), count)` before,\n",
    "\n",
    "but now it should looke like\n",
    "\n",
    "`(packageManager, (repositoryOwner, count))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_reformated ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is in the right format, use `reduceByKey` and `max` to find the most prominent owner per package manager.\n",
    "\n",
    "Hint: remember that the `max` function in python can take a `key` value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxes ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `map` to reformat the data one more time, into a 3-tuple per element.\n",
    "\n",
    "When you are done, your data should look like\n",
    "\n",
    "`(packageMananger, repositoryOwner, count)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxes_reformatted = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use `collect` to display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the correlation between number of github stars and number of times a package is listed as a dependency?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will be working with the joined RDD.\n",
    "\n",
    "First we need to retrieve the two pieces of information we need from each element in the RDD.\n",
    "\n",
    "Because some of the elements of the RDD don't have this information, we have written the function below to assign 0 to missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_to_int(string):\n",
    "    try:\n",
    "        return int(string)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to extract the two numbers we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_and_deps = joined.map(lambda x: (turn_to_int(x[1][0][19]),turn_to_int(x[1][1][10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use reduce to add up the number of stars and dependencies. We have done this step for you because calling reduce on tuples can be tricky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stars = stars_and_deps.reduce(lambda x,y: (x[0] + y[0],))[0]/stars_and_deps.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_deps = stars_and_deps.reduce(lambda x,y: (1,x[1] + y[1]))[1]/stars_and_deps.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `map` to calculate the errors for each element in the RDD, by subtracting either `mean_stars`, or `mean_deps` from the appropriate value in the tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `map` to square each value of the tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_errors ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `reduce` to calculate the sums of the squared errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_of_squares = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the denominator by taking the square root of each sum and multiplying them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next use `map` to multiply together the error for the stars and the error for the dependencies for each element in the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the numerator of the equation by using `reduce` to sum all the products from the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, get the correlation by dividing the numerator by the denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which package names are found in both npm and pypi\n",
    "For the final question, we are going to use set operations.\n",
    "\n",
    "First we need to find the packages in pypi and the packages in NPM\n",
    "\n",
    "Use `filter` to find all the elements of the RDD whose first value is equal to \"Pypi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pypi = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `filter` to find all the elements of the RDD whose first value is equal to \"NPM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npm = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `map` to get an RDD of only the names of the pypi packages. The names are the 2nd value of the tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pypi_names ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `map` to get an RDD of only the names of the npm packages. The names are the 2nd value of the tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npm_names ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `intersection` to get the names that appear in both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the names that appear in both by calling `collect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
