{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparkSQL Lab\n",
    "\n",
    "In this lab, we will be working with data from [Libraries.io](http://Libraries.io), a package manager aggregator. Our data consist of two files, one detailing packages and package managers, the other detailing the code repositories the packages are developed in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"hdfs:///user/bryan/data/projects-1.0.0-2017-06-15.csv\",header=True, inferSchema=True, mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('SourceRank', data.SourceRank.cast(\"double\"))\n",
    "data = data.withColumn('Dependent Repositories Count', data[\"Dependent Repositories Count\"].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the data available to SQL using `createTempView`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the lab consists of answering questions about the data. \n",
    "\n",
    "### How many packages are accounted for in this dataset?\n",
    "\n",
    "Hint: Use `count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What package managers are included in the data?\n",
    "\n",
    "The package manager is in the column named 'platform'\n",
    "\n",
    "Hint: `DISTINCT` can be used right in a `SELECT` statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the results using `collect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What package has the higest SourceRank?\n",
    "\n",
    "SourceRank is Libraries.io measure that combines popularity as well as how well maintained the packages is, along with a few other factors\n",
    "\n",
    "Use `max` to find the largest SourceRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a `WHERE` clause to select the row of the DataFrame that has the highest SourceRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSR = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `show` to display the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSR.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the most frequent dependency per package manager?\n",
    "\n",
    "To answer this question, let's break it down into smaller parts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next use `groupBy` and `max` to find the highest number of \"Dependent Repositories Count\" per package manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deps = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `show` to look at this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deps.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the column name includes the name of the aggregate function, in this case `max`. Re-write the query above using `AS` so this doesn't happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deps = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above query as a subquery, and filter out any rows that have a \"Dependent Repositories Count\" of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deps = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your work using `show`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deps.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use `join` to join data with the above query (we've done this for you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deps_info = max_deps = spark.sql(\"\"\"\n",
    "    SELECT data.platform, name, data.`Dependent Repositories Count` FROM data \n",
    "    JOIN (SELECT platform,`Dependent Repositories Count` FROM \n",
    "            (SELECT platform, max(`Dependent Repositories Count`) AS `Dependent Repositories Count` \n",
    "                    FROM data GROUP BY platform) WHERE `Dependent Repositories Count` != 0) AS X \n",
    "    ON X.`Dependent Repositories Count` == data.`Dependent Repositories Count` AND X.platform == data.platform\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `show` after to see the results. Pass a number to `show` so that all the results are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who is the most proflific owner of packages per package manager?\n",
    "\n",
    "For this next question, we need to consult the second file, which is detailed information about where and who develops each package. Reading in the data will be very similar to as was done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_data = spark.read.csv(\"hdfs:///user/bryan/data/repositories-1.0.0-2017-06-15.csv\",header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_data.createTempView(\"repos_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the owner into its own column, we are going to use the function `regexp_extract`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_data = spark.sql(\"\"\"SELECT *,regexp_extract(`Name With Owner`,'(.*)/',0) AS owner\n",
    "                          FROM repos_data \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use `join` to create a joined DataFrame. The columns to join on are \"ID\" from the subquery above, and \"Repository ID\" from `data`. It will be helpful to use a subquery and the keyword `AS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put this table back into the SQL catalog by using `createTempView`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the package owner information joined with the package, use `groupby` and `count` to see how many packages each owner has per package manager.\n",
    "\n",
    "The relevant columns are \"Platform\" and \"owner\"\n",
    "\n",
    "Hint: `groupBy` can take more than one column to group on. Use `AS` to give the aggregate function a good name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to deterimine the max count per platform. Do this using `groupby` and `max`, using the previous query as a subquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we want to remove the name of the function from the column name, so re-write the query above to use `AS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the owner with the most packages per package manager can be found by using `join` on `counts` and `max_count`\n",
    "\n",
    "Call `show` after joining to see the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"SELECT A.platform, A.owner, A.count FROM\n",
    "                (SELECT platform, owner, count(*) as count from joined GROUP BY platform, owner) AS A\n",
    "                    JOIN\n",
    "                       ( SELECT platform, max(count) AS count FROM\n",
    "                      (SELECT platform, owner, count(*) AS count from joined GROUP BY platform, owner)\n",
    "                      GROUP BY platform) AS B\n",
    "                      on A.platform = B.platform AND A.count = B.count\n",
    "                      \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the correlation between number of github stars and number of times a package is listed as a dependency?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `corr` on the table, passing it the correct column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which package names are found in both npm and pypi\n",
    "For the final question, we are going to use set operations.\n",
    "\n",
    "First we need to find the packages in pypi and the packages in NPM\n",
    "\n",
    "Use `WHERE` to find all the elements of the DataFrame whose \"Platform\" is equal to \"Pypi\", and `SELECT` to only return the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `WHERE` to find all the elements of the DataFrame whose \"Platform\" is equal to \"NPM\", and `SELECT` to only return the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `INTERSECT` to get the names that appear in both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the names that appear in both by calling `show`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
